#!/usr/bin/env python

import logging
import json
import signal

import click
from clickhouse_driver import Client
from kafka import KafkaConsumer

from snuba import settings
from snuba.writer import SnubaWriter


shutdown = False
logger = logging.getLogger('snuba.writer')


def handler(signum, frame):
    global shutdown
    shutdown = True

    logger.warning("SIGINT received, initiating shutdown")


signal.signal(signal.SIGINT, handler)


@click.command()
@click.option('--processed-events-topic', default=settings.WRITER_TOPIC,
              help='Topic to consume processed events from.')
@click.option('--consumer-group', default=settings.WRITER_CONSUMER_GROUP,
              help='Consumer group used for consuming the processed events topic.')
@click.option('--bootstrap-server', default=settings.BROKERS, multiple=True,
              help='Kafka bootstrap server to use (multiple allowed).')
@click.option('--clickhouse-server', default=settings.CLICKHOUSE_NODES, multiple=True,
              help='Clickhouse server to write to (multiple allowed).')
@click.option('--log-level', default='WARN', help='Logging level to use.')
def run(processed_events_topic, consumer_group, bootstrap_server, clickhouse_server, log_level):
    logging.basicConfig(level=getattr(logging, log_level.upper()))

    connections = [Client(node) for node in clickhouse_server]

    # ensure tables exist
    for conn in connections:
        conn.execute(settings.LOCAL_TABLE_DEFINITION)
        conn.execute(settings.DIST_TABLE_DEFINITION)

    consumer = KafkaConsumer(
        processed_events_topic,
        bootstrap_servers=bootstrap_server,
        group_id=consumer_group,
        auto_offset_reset='earliest',
        consumer_timeout_ms=1000,
    )

    writer = SnubaWriter(connections=connections)

    while not shutdown:
        for msg in consumer:
            writer.write(json.loads(msg.value))

            if shutdown:
                break

    # shutdown
    writer.flush()


if __name__ == '__main__':
    run()
