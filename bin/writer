#!/usr/bin/env python

import logging
import json
import signal

import click
from clickhouse_driver import Client

from snuba import settings
from snuba.consumer import AbstractBatchWorker, BatchingKafkaConsumer
from snuba.writer import SnubaWriter, row_from_processed_event


shutdown = False
logger = logging.getLogger('snuba.writer')


def handler(signum, frame):
    global shutdown
    shutdown = True

    logger.warning("SIGINT received, initiating shutdown")


signal.signal(signal.SIGINT, handler)


@click.command()
@click.option('--processed-events-topic', default=settings.WRITER_TOPIC,
              help='Topic to consume processed events from.')
@click.option('--consumer-group', default=settings.WRITER_CONSUMER_GROUP,
              help='Consumer group used for consuming the processed events topic.')
@click.option('--bootstrap-server', default=settings.BROKERS, multiple=True,
              help='Kafka bootstrap server to use (multiple allowed).')
@click.option('--clickhouse-server', default=settings.CLICKHOUSE_NODES, multiple=True,
              help='Clickhouse server to write to (multiple allowed).')
@click.option('--log-level', default='WARN', help='Logging level to use.')
def run(processed_events_topic, consumer_group, bootstrap_server, clickhouse_server, log_level):
    logging.basicConfig(level=getattr(logging, log_level.upper()))

    connections = [Client(node) for node in clickhouse_server]

    # ensure tables exist
    for conn in connections:
        conn.execute(settings.LOCAL_TABLE_DEFINITION)
        conn.execute(settings.DIST_TABLE_DEFINITION)

    writer = SnubaWriter(connections=connections)

    class WriterWorker(AbstractBatchWorker):
        def process_message(self, message):
            return row_from_processed_event(json.loads(message.value), settings.WRITER_COLUMNS)

        def flush_batch(self, batch):
            writer.write(batch)

        def shutdown(self):
            pass

    consumer = BatchingKafkaConsumer(
        processed_events_topic,
        worker=WriterWorker(),
        max_batch_size=100000,
        max_batch_time=30 * 1000,
        bootstrap_servers=bootstrap_server,
        group_id=consumer_group,
        auto_offset_reset='earliest',
        consumer_timeout_ms=1000,
    )

    def handler(signum, frame):
        consumer.signal_shutdown()

    signal.signal(signal.SIGINT, handler)

    consumer.run()


if __name__ == '__main__':
    run()
